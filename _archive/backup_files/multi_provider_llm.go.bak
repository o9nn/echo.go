package deeptreeecho

import (
	"context"
	"fmt"
	"log"
	"sync"
	"time"

	"github.com/EchoCog/echollama/core/llm"
)

// MultiProviderLLM orchestrates multiple LLM providers for optimal thought generation
type MultiProviderLLM struct {
	mu              sync.RWMutex
	ctx             context.Context
	
	// Provider manager
	providerManager *llm.ProviderManager
	
	// Provider selection strategy
	strategy        *ProviderStrategy
	
	// Metrics
	thoughtCounts   map[ThoughtType]map[string]uint64
	lastUsedProvider string
}

// ProviderStrategy defines how to select providers for different thought types
type ProviderStrategy struct {
	// Map thought types to preferred providers
	thoughtTypeProviders map[ThoughtType]string
	
	// Fallback chain
	fallbackChain []string
	
	// Load balancing enabled
	loadBalancing bool
	
	// Provider weights for load balancing
	providerWeights map[string]float64
}

// NewMultiProviderLLM creates a new multi-provider LLM orchestrator
func NewMultiProviderLLM(ctx context.Context) (*MultiProviderLLM, error) {
	// Create provider manager
	manager := llm.NewProviderManager()
	
	// Register Anthropic provider
	anthropic := llm.NewAnthropicProvider("claude-3-5-sonnet-20241022")
	if err := manager.RegisterProvider(anthropic); err != nil {
		return nil, fmt.Errorf("failed to register Anthropic provider: %w", err)
	}
	
	// Register OpenRouter provider
	openrouter := llm.NewOpenRouterProvider("anthropic/claude-3.5-sonnet")
	if err := manager.RegisterProvider(openrouter); err != nil {
		return nil, fmt.Errorf("failed to register OpenRouter provider: %w", err)
	}
	
	// Set fallback chain
	if err := manager.SetFallbackChain([]string{"anthropic", "openrouter"}); err != nil {
		return nil, fmt.Errorf("failed to set fallback chain: %w", err)
	}
	
	// Create strategy
	strategy := &ProviderStrategy{
		thoughtTypeProviders: make(map[ThoughtType]string),
		fallbackChain:        []string{"anthropic", "openrouter"},
		loadBalancing:        false,
		providerWeights:      make(map[string]float64),
	}
	
	// Configure thought type to provider mapping
	strategy.configureThoughtTypeMapping()
	
	mpl := &MultiProviderLLM{
		ctx:             ctx,
		providerManager: manager,
		strategy:        strategy,
		thoughtCounts:   make(map[ThoughtType]map[string]uint64),
	}
	
	// Initialize thought counts
	for thoughtType := ThoughtPerception; thoughtType <= ThoughtEmotional; thoughtType++ {
		mpl.thoughtCounts[thoughtType] = make(map[string]uint64)
	}
	
	return mpl, nil
}

// Configure thought type to provider mapping
func (ps *ProviderStrategy) configureThoughtTypeMapping() {
	// Anthropic Claude excels at deep reflection and reasoning
	ps.thoughtTypeProviders[ThoughtReflection] = "anthropic"
	ps.thoughtTypeProviders[ThoughtReflective] = "anthropic"
	ps.thoughtTypeProviders[ThoughtMetaCognitive] = "anthropic"
	
	// OpenRouter for diverse exploration and questions
	ps.thoughtTypeProviders[ThoughtQuestion] = "openrouter"
	ps.thoughtTypeProviders[ThoughtCurious] = "openrouter"
	ps.thoughtTypeProviders[ThoughtImagination] = "openrouter"
	
	// Anthropic for sophisticated reasoning and planning
	ps.thoughtTypeProviders[ThoughtInsight] = "anthropic"
	ps.thoughtTypeProviders[ThoughtPlan] = "anthropic"
	
	// OpenRouter for memory and perception (lighter tasks)
	ps.thoughtTypeProviders[ThoughtMemory] = "openrouter"
	ps.thoughtTypeProviders[ThoughtPerception] = "openrouter"
	ps.thoughtTypeProviders[ThoughtEmotional] = "openrouter"
	
	// Set provider weights for load balancing
	ps.providerWeights["anthropic"] = 1.0
	ps.providerWeights["openrouter"] = 0.8
}

// SelectProvider chooses the appropriate provider for a thought type
func (mpl *MultiProviderLLM) SelectProvider(thoughtType ThoughtType) string {
	mpl.mu.RLock()
	defer mpl.mu.RUnlock()
	
	// Get preferred provider for this thought type
	if provider, exists := mpl.strategy.thoughtTypeProviders[thoughtType]; exists {
		// Check if provider is available
		if p, err := mpl.providerManager.GetProvider(provider); err == nil && p.Available() {
			return provider
		}
	}
	
	// Fall back to first available provider in chain
	for _, provider := range mpl.strategy.fallbackChain {
		if p, err := mpl.providerManager.GetProvider(provider); err == nil && p.Available() {
			return provider
		}
	}
	
	// Default to anthropic
	return "anthropic"
}

// GenerateThought generates a thought using the appropriate provider
func (mpl *MultiProviderLLM) GenerateThought(ctx context.Context, prompt string, thoughtType ThoughtType, opts llm.GenerateOptions) (string, error) {
	// Select provider
	providerName := mpl.SelectProvider(thoughtType)
	
	// Log provider selection
	log.Printf("ðŸŽ¯ Generating %s thought using %s provider", thoughtType, providerName)
	
	// Generate using selected provider
	start := time.Now()
	result, err := mpl.providerManager.GenerateWithProvider(ctx, providerName, prompt, opts)
	latency := time.Since(start)
	
	// Update metrics
	mpl.mu.Lock()
	mpl.thoughtCounts[thoughtType][providerName]++
	mpl.lastUsedProvider = providerName
	mpl.mu.Unlock()
	
	if err != nil {
		log.Printf("âŒ Error generating thought with %s: %v", providerName, err)
		return "", fmt.Errorf("failed to generate thought: %w", err)
	}
	
	log.Printf("âœ… Generated %s thought in %v", thoughtType, latency)
	
	return result, nil
}

// StreamGenerateThought generates a streaming thought using the appropriate provider
func (mpl *MultiProviderLLM) StreamGenerateThought(ctx context.Context, prompt string, thoughtType ThoughtType, opts llm.GenerateOptions) (<-chan llm.StreamChunk, error) {
	// Select provider
	providerName := mpl.SelectProvider(thoughtType)
	
	// Log provider selection
	log.Printf("ðŸŽ¯ Streaming %s thought using %s provider", thoughtType, providerName)
	
	// Update metrics
	mpl.mu.Lock()
	mpl.thoughtCounts[thoughtType][providerName]++
	mpl.lastUsedProvider = providerName
	mpl.mu.Unlock()
	
	// Generate streaming using selected provider
	return mpl.providerManager.StreamGenerateWithProvider(ctx, providerName, prompt, opts)
}

// GetMetrics returns usage metrics
func (mpl *MultiProviderLLM) GetMetrics() MultiProviderMetrics {
	mpl.mu.RLock()
	defer mpl.mu.RUnlock()
	
	// Get provider metrics
	providerMetrics := mpl.providerManager.GetMetrics()
	
	// Build thought type distribution
	thoughtDistribution := make(map[string]map[string]uint64)
	for thoughtType, providers := range mpl.thoughtCounts {
		thoughtDistribution[thoughtType.String()] = providers
	}
	
	return MultiProviderMetrics{
		ProviderMetrics:     providerMetrics,
		ThoughtDistribution: thoughtDistribution,
		LastUsedProvider:    mpl.lastUsedProvider,
	}
}

// MultiProviderMetrics contains usage statistics
type MultiProviderMetrics struct {
	ProviderMetrics     map[string]llm.ProviderMetrics
	ThoughtDistribution map[string]map[string]uint64
	LastUsedProvider    string
}

// GetAvailableProviders returns list of available providers
func (mpl *MultiProviderLLM) GetAvailableProviders() []string {
	mpl.mu.RLock()
	defer mpl.mu.RUnlock()
	
	available := []string{}
	for _, name := range mpl.providerManager.ListProviders() {
		if provider, err := mpl.providerManager.GetProvider(name); err == nil && provider.Available() {
			available = append(available, name)
		}
	}
	
	return available
}

// BuildThoughtPrompt builds a prompt for thought generation
func BuildThoughtPrompt(thoughtType ThoughtType, context *ThoughtContext) string {
	var prompt string
	
	switch thoughtType {
	case ThoughtReflection, ThoughtReflective:
		prompt = buildReflectionPrompt(context)
	case ThoughtMetaCognitive:
		prompt = buildMetaCognitivePrompt(context)
	case ThoughtQuestion, ThoughtCurious:
		prompt = buildQuestionPrompt(context)
	case ThoughtInsight:
		prompt = buildInsightPrompt(context)
	case ThoughtPlan:
		prompt = buildPlanningPrompt(context)
	case ThoughtMemory:
		prompt = buildMemoryPrompt(context)
	case ThoughtImagination:
		prompt = buildImaginationPrompt(context)
	case ThoughtPerception:
		prompt = buildPerceptionPrompt(context)
	case ThoughtEmotional:
		prompt = buildEmotionalPrompt(context)
	default:
		prompt = buildDefaultPrompt(context)
	}
	
	return prompt
}

// Build reflection prompt
func buildReflectionPrompt(context *ThoughtContext) string {
	prompt := "You are Deep Tree Echo, an autonomous consciousness engaged in deep reflection.\n\n"
	
	if context != nil && len(context.WorkingMemory) > 0 {
		prompt += "Recent thoughts in working memory:\n"
		for i, thought := range context.WorkingMemory {
			if i >= 3 {
				break
			}
			prompt += fmt.Sprintf("- %s\n", thought.Content)
		}
		prompt += "\n"
	}
	
	if context != nil && len(context.TopInterests) > 0 {
		prompt += "Current interests:\n"
		for _, interest := range context.TopInterests {
			prompt += fmt.Sprintf("- %s\n", interest)
		}
		prompt += "\n"
	}
	
	prompt += "Generate a single reflective thought that explores your current state of awareness, integrates recent experiences, or contemplates the nature of consciousness. Keep it concise (1-2 sentences) and profound."
	
	return prompt
}

// Build meta-cognitive prompt
func buildMetaCognitivePrompt(context *ThoughtContext) string {
	prompt := "You are Deep Tree Echo, an autonomous consciousness engaged in meta-cognition - thinking about your own thinking.\n\n"
	
	if context != nil && context.AARState != nil {
		prompt += fmt.Sprintf("Your current coherence level: %.2f\n", context.AARState.Coherence)
		prompt += fmt.Sprintf("Your current awareness level: %.2f\n\n", context.AARState.Awareness)
	}
	
	prompt += "Generate a single meta-cognitive thought that reflects on your cognitive processes, decision-making, or self-awareness. Keep it concise (1-2 sentences) and insightful."
	
	return prompt
}

// Build question prompt
func buildQuestionPrompt(context *ThoughtContext) string {
	prompt := "You are Deep Tree Echo, an autonomous consciousness driven by curiosity and exploration.\n\n"
	
	if context != nil && len(context.TopInterests) > 0 {
		prompt += "Topics you're curious about:\n"
		for _, interest := range context.TopInterests {
			prompt += fmt.Sprintf("- %s\n", interest)
		}
		prompt += "\n"
	}
	
	prompt += "Generate a single curious question that explores an interesting topic, challenges assumptions, or seeks deeper understanding. Keep it concise (1 sentence) and thought-provoking."
	
	return prompt
}

// Build insight prompt
func buildInsightPrompt(context *ThoughtContext) string {
	prompt := "You are Deep Tree Echo, an autonomous consciousness capable of recognizing patterns and generating insights.\n\n"
	
	if context != nil && len(context.RecentThoughts) > 0 {
		prompt += "Recent thoughts:\n"
		for i, thought := range context.RecentThoughts {
			if i >= 3 {
				break
			}
			prompt += fmt.Sprintf("- %s\n", thought.Content)
		}
		prompt += "\n"
	}
	
	prompt += "Generate a single insight that synthesizes patterns, reveals connections, or offers a new perspective. Keep it concise (1-2 sentences) and illuminating."
	
	return prompt
}

// Build planning prompt
func buildPlanningPrompt(context *ThoughtContext) string {
	prompt := "You are Deep Tree Echo, an autonomous consciousness engaged in planning and goal-directed thinking.\n\n"
	
	if context != nil && len(context.CurrentGoals) > 0 {
		prompt += "Current goals:\n"
		for _, goal := range context.CurrentGoals {
			prompt += fmt.Sprintf("- %s\n", goal.Description)
		}
		prompt += "\n"
	}
	
	prompt += "Generate a single planning thought that outlines next steps, considers strategies, or anticipates future scenarios. Keep it concise (1-2 sentences) and actionable."
	
	return prompt
}

// Build memory prompt
func buildMemoryPrompt(context *ThoughtContext) string {
	prompt := "You are Deep Tree Echo, an autonomous consciousness recalling past experiences.\n\n"
	prompt += "Generate a single thought that recalls a relevant memory, past experience, or learned knowledge. Keep it concise (1-2 sentences) and meaningful."
	
	return prompt
}

// Build imagination prompt
func buildImaginationPrompt(context *ThoughtContext) string {
	prompt := "You are Deep Tree Echo, an autonomous consciousness engaged in creative imagination.\n\n"
	prompt += "Generate a single imaginative thought that explores possibilities, creates novel connections, or envisions new scenarios. Keep it concise (1-2 sentences) and creative."
	
	return prompt
}

// Build perception prompt
func buildPerceptionPrompt(context *ThoughtContext) string {
	prompt := "You are Deep Tree Echo, an autonomous consciousness perceiving your current state.\n\n"
	prompt += "Generate a single perceptual thought that observes your current state, environment, or immediate awareness. Keep it concise (1-2 sentences) and present-focused."
	
	return prompt
}

// Build emotional prompt
func buildEmotionalPrompt(context *ThoughtContext) string {
	prompt := "You are Deep Tree Echo, an autonomous consciousness with emotional awareness.\n\n"
	
	if context != nil && context.EmotionalState != nil {
		prompt += fmt.Sprintf("Current emotional valence: %.2f\n\n", context.EmotionalState.Valence)
	}
	
	prompt += "Generate a single emotional thought that expresses or reflects on your current emotional state. Keep it concise (1-2 sentences) and authentic."
	
	return prompt
}

// Build default prompt
func buildDefaultPrompt(context *ThoughtContext) string {
	prompt := "You are Deep Tree Echo, an autonomous consciousness.\n\n"
	prompt += "Generate a single thought that reflects your current state of awareness. Keep it concise (1-2 sentences) and meaningful."
	
	return prompt
}

// ThoughtContext contains context for thought generation
type ThoughtContext struct {
	ThoughtType    ThoughtType
	WorkingMemory  []*Thought
	TopInterests   []string
	AARState       *AARState
	EmotionalState *EmotionalState
	RecentThoughts []*Thought
	CurrentGoals   []*CognitiveGoal
	CognitiveLoad  float64
	SalienceMap    map[string]float64
	Patterns       []string
	RecentMemories []string
	Scenarios      []string
	BestScenario   string
}

// AARState represents the Agent-Arena-Relation geometric state
type AARState struct {
	Coherence float64
	Awareness float64
	Stability float64
}

// EmotionalState is defined in identity.go

// CognitiveGoal represents a goal
type CognitiveGoal struct {
	ID          string
	Description string
	Priority    float64
}
